{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzJseU_dQvfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mounting google drive to colab, and unzipping the training data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip 'drive/My Drive/out.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcdgCntiROEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms, utils\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tnyiTLZaYEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize hyperparameters and constants\n",
        "\n",
        "dir_name = 'out'\n",
        "height = 32\n",
        "width = 100\n",
        "valid_ratio = 0.02\n",
        "\n",
        "num_rnn_inp = 512 #number of neurons in RNN input layer\n",
        "num_rnn_hid = 256 #number of neurons in RNN hidden layer\n",
        "\n",
        "num_epochs = 5\n",
        "batch_num = 64\n",
        "learning_rate = 0.00005\n",
        "\n",
        "train_loss_step = 20 \n",
        "val_acc_step = 100\n",
        "display_label_step = 100\n",
        "save_mode_step = 1000\n",
        "\n",
        "blank_label = '~'\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd8RFVfep5T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create vocabulory from all the input lables \n",
        "img_names = [i[:-4] for i in os.listdir('out')]\n",
        "labels = [i.split('_')[0] for i in img_names]\n",
        "all_chars_combined = ''.join(labels)\n",
        "vocab = list(set(all_chars_combined))\n",
        "vocab.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyL8JC7bp8kJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_rnn_out = len(vocab) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17g4S5jJqAc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in CTC loss 0 is defaulted for empty char. Start from 1\n",
        "\n",
        "idx2char = {i+1:val for i,val in enumerate(vocab)}\n",
        "char2idx = {val:i+1 for i,val in enumerate(vocab)}\n",
        "idx2char[0] = blank_label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOgFhaSuqDWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pytorch Dataset define\n",
        "\n",
        "class OCRDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.img_names = os.listdir(img_dir)\n",
        "        self.img_names.sort()\n",
        "        \n",
        "        self.labels = []\n",
        "        for img_name in self.img_names:\n",
        "            self.labels.append(img_name.split('_')[0])\n",
        "        \n",
        "        self.img_names = [os.path.join(img_dir, img_name) for img_name in self.img_names]\n",
        "        \n",
        "       \n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_names[idx]\n",
        "        img = Image.open(img_name)\n",
        "        \n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            \n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        return (img, label)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JyHwl9pqGHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((height,width)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH_6RYgmqIvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode string to output and decode output to string\n",
        "\n",
        "def encodeString(label):\n",
        "    encoded = [char2idx[char] for char in label]\n",
        "    return encoded\n",
        "\n",
        "def encodeLabel(label_batch):\n",
        "    combined = ''\n",
        "    lengths = []\n",
        "    for label in label_batch:\n",
        "        combined += label\n",
        "        lengths.append(len(label))\n",
        "    return torch.IntTensor(encodeString(combined)), torch.IntTensor(lengths)\n",
        "\n",
        "\n",
        "def decodeLable(pred):\n",
        "    predict_labels = []\n",
        "    out = pred.argmax(dim=2)\n",
        "    out = out.permute(1,0)\n",
        "    for y in out: \n",
        "        lab = ''\n",
        "        for yi in y:\n",
        "            lab += idx2char[yi.item()]\n",
        "            \n",
        "        lab += blank_label\n",
        "        \n",
        "        final_lab = ''\n",
        "        for i in range(len(lab)):\n",
        "            if (lab[i] != blank_label) and (lab[i] != lab[i+1]) :\n",
        "                final_lab += lab[i]\n",
        "        final_lab = final_lab.lower()\n",
        "        \n",
        "        predict_labels.append(final_lab)\n",
        "    return predict_labels\n",
        "\n",
        "\n",
        "def getAccuracy(actuals, predicted):\n",
        "    correct = 0\n",
        "    for act,pred in zip(actuals, predicted):\n",
        "        if (act.lower() == pred):\n",
        "            correct += 1\n",
        "    return correct\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOgqFyFSqLVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b8c083f8-ec70-466f-d66a-212aa4de7127"
      },
      "source": [
        "data_loader = OCRDataset(dir_name, transform)\n",
        "\n",
        "train, valid = random_split(data_loader, [int(len(data_loader)*(1-valid_ratio)), int(len(data_loader)*valid_ratio)])\n",
        "\n",
        "print(len(train))\n",
        "print(len(valid))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "196000\n",
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO69RUohqPoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define CRNN model\n",
        "\n",
        "class CNNFeatureGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNFeatureGenerator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(64,128,3,1,1)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        self.conv3 = nn.Conv2d(128,256,3,1,1)\n",
        "        self.conv4 = nn.Conv2d(256,256,3,1,1)\n",
        "        self.pool3 = nn.MaxPool2d((2,2),(2,1),(0,1))\n",
        "        self.conv5 = nn.Conv2d(256,512,3,1,1)\n",
        "        self.bn1 = nn.BatchNorm2d(512)\n",
        "        self.conv6 = nn.Conv2d(512,512,3,1,1)\n",
        "        self.bn2 = nn.BatchNorm2d(512)\n",
        "        self.pool4 = nn.MaxPool2d((2,2),(2,1),(0,1))\n",
        "        self.conv7 = nn.Conv2d(512,512,2,1,0)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.bn1(self.conv5(x)))\n",
        "        x = F.relu(self.bn2(self.conv6(x)))\n",
        "        x = self.pool4(F.relu(self.conv7(x)))\n",
        "        \n",
        "        x = x.squeeze(2)\n",
        "        x = x.permute(2,0,1)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "class BidirectionalLSTM(nn.Module):\n",
        "    def __init__(self,inp_size, hid_size, out_size):\n",
        "        super(BidirectionalLSTM, self).__init__()\n",
        "        self.inp2hid = nn.LSTM(inp_size, hid_size, bidirectional=True)\n",
        "        self.hid2out = nn.Linear(2*hid_size, out_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        output, _ = self.inp2hid(x)\n",
        "        s, b, n = output.size()\n",
        "        output = self.hid2out(output.view(s*b, n))\n",
        "        output = output.view(s,b,-1)\n",
        "        \n",
        "        return output\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, rnn_inp_size, rnn_hid_size, rnn_out_size):\n",
        "        super(CRNN, self).__init__()\n",
        "        self.cnn = CNNFeatureGenerator()\n",
        "        self.rnn1 = BidirectionalLSTM(rnn_inp_size, rnn_hid_size, rnn_hid_size)\n",
        "        self.rnn2 = BidirectionalLSTM(rnn_hid_size, rnn_hid_size, rnn_out_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rnn1(x)\n",
        "        x = self.rnn2(x)\n",
        "        x = F.log_softmax(x, dim=2)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmuF2NZj89yv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8dea96db-1fa1-4625-970e-f7009c0a109a"
      },
      "source": [
        "device.type"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js1mcM0UqZRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "aca7cdbe-ac5d-44b9-ea43-6495cb7ecaba"
      },
      "source": [
        "crnn = CRNN(num_rnn_inp, num_rnn_hid, num_rnn_out).to(device)\n",
        "\n",
        "\n",
        "# In case labels are completely inprobable (ex - lenght = 0), loss can go to inf\n",
        "# Taking care of NaN loss during training\n",
        "def backward_hook(self, grad_input, grad_output):\n",
        "  for g in grad_input:\n",
        "      g[g != g] = 0   # replace all nan/inf in gradients to zero\n",
        "\n",
        "\n",
        "crnn.register_backward_hook(backward_hook)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f435a4c1668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nnh-kMzUqcaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CTCLoss().to(device)\n",
        "optimizer = optim.Adam(crnn.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWQCp8PRqeYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word level accuracy on validation set\n",
        "\n",
        "def validationAccuracy(valid_data):\n",
        "    valid_loader = DataLoader(valid_data, batch_size=batch_num)\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(valid_loader, 0):\n",
        "        inputs, labels = data\n",
        "        preds = crnn(inputs.to(device))\n",
        "        pred_labs = decodeLable(preds)\n",
        "        \n",
        "        num_correct += getAccuracy(labels, pred_labs)\n",
        "    \n",
        "    accuracy = num_correct/len(valid_data)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK5Wtoa9qgZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_hist = []\n",
        "valid_hist = []\n",
        "\n",
        "\n",
        "# Trainign begins here\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loader = DataLoader(train, batch_size=batch_num, shuffle=True)\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # start = time.time()\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        if (len(labels) != batch_num):\n",
        "            continue\n",
        "        \n",
        "        # forward \n",
        "        preds = crnn(inputs)\n",
        "        input_lengths = torch.IntTensor([preds.size(0)] * batch_num)\n",
        "        targets, target_lengths = encodeLabel(labels)\n",
        "        \n",
        "        '''\n",
        "        input for CTC loss pytorch \n",
        "            Log_probs - Tensor of size (T, N, C) T = input length , N = batch size and C =number of classes with blank\n",
        "            Targets - Tensor of size (N, S) or (sum of target lenghts)\n",
        "            Input_lengths - tuple or tensor of size n where n = batch size\n",
        "            Target_lengths - tuple or tensor of size n where n = batch size\n",
        "        \n",
        "        For batch size as 2\n",
        "            input lengths = tensor([26, 26], dtype=torch.int32)\n",
        "            target lengths = tensor([13,  5], dtype=torch.int32)\n",
        "            targets = tensor([30, 18, 15, 11, 30, 30, 19, 13, 11, 22, 19, 29, 23, 20, 11, 19, 22, 29], dtype=torch.int32)\n",
        "       \n",
        "           in this case labels are - ('theatticalism', 'jails')\n",
        "        '''\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backward + optimize\n",
        "        loss = criterion(preds, targets, input_lengths, target_lengths) /batch_num\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # end = time.time()\n",
        "\n",
        "        # print(\"time is \" + str(end-start))\n",
        "        \n",
        "        #print actual and predicted label\n",
        "        if i%display_label_step == (display_label_step-1):\n",
        "            out_labels = torch.argmax(preds,dim=2)\n",
        "            out = [idx2char[i[0].item()] if i[0].item() != 0 else blank_label for i in out_labels[:,0:1]]\n",
        "            out = ''.join(out)\n",
        "            print ('-------------------------------------------------------------------')\n",
        "            print (out  + \" ||||| \" + labels[0])\n",
        "            print ('-------------------------------------------------------------------')\n",
        "            \n",
        "        #print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % train_loss_step == (train_loss_step-1):    # print every train_loss_step mini-batches\n",
        "            print('[%d, %5d] loss: %f' %\n",
        "                  (epoch + 1, i + 1, running_loss / train_loss_step))\n",
        "            loss_hist.append(running_loss / train_loss_step)\n",
        "            running_loss = 0.0\n",
        "        \n",
        "        #print accuracy\n",
        "        if i %val_acc_step == (val_acc_step - 1):\n",
        "            print ('-------------------------------------------------------------------')\n",
        "            print('validation Accuracy = ' + str(validationAccuracy(valid)))\n",
        "            valid_hist.append(validationAccuracy(valid))\n",
        "            print ('-------------------------------------------------------------------')\n",
        "            \n",
        "        if i %save_mode_step == (save_mode_step - 1):\n",
        "            torch.save(crnn, 'drive/My Drive/saved_models_crnn/epoch_' + str(epoch) + ' ' + 'iter_' + str(i) + '.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}